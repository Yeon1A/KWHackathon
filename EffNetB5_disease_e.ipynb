{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yeon1A/KWHackathon/blob/main/EffNetB5_disease_e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU8lLyA7APXo",
        "outputId": "51fc246c-b541-4072-a125-cf279285ec6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/612.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "### 라이브러리\n",
        "!pip install tensorflow-addons\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Input,GlobalAveragePooling2D, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, AveragePooling2D, Flatten, Dense, ZeroPadding2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import random\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "os.environ['PYTHONHASHSEED']='1'\n",
        "os.environ['TF_DETERMINISTIC_OPS']='1'\n",
        "np.random.seed(5148)\n",
        "random.seed(5148)\n",
        "tf.random.set_seed(5148)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNIRBCgIuBSj"
      },
      "outputs": [],
      "source": [
        "#%% GPU 할당\n",
        "\n",
        "# GPU를 사용할 수 있는지 확인\n",
        "#physical_devices = tf.config.list_physical_devices('GPU')\n",
        "#if len(physical_devices) == 0:\n",
        "#    print(\"GPU를 찾을 수 없습니다. CPU를 사용합니다.\")\n",
        "#else:\n",
        "#    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "#    print(\"GPU를 사용합니다.\")\n",
        "\n",
        "\n",
        "#%% GPU 할당\n",
        "\n",
        "# GPU를 사용할 수 있는지 확인\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.set_logical_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.LogicalDeviceConfiguration(memory_limit=10*1024)])\n",
        "  except RuntimeError as e:\n",
        "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv0eBsRBD9Ab",
        "outputId": "ea50ea27-9201-4371-f7ec-ea4baed46baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive    # google drive mount\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RylvNz8g-glK"
      },
      "outputs": [],
      "source": [
        "#%% B0 (224,224)\n",
        "\n",
        "se_ratio = 4\n",
        "expand_ratio = 6\n",
        "#width_coefficient = 1.0 #B0\n",
        "width_coefficient = 1.0 #B5 (456,456)\n",
        "\n",
        "#depth_coefficient = 1.0 #B0\n",
        "depth_coefficient = 2.2 #B5 (456,456)\n",
        "\n",
        "#default_resolution = 224 #B0\n",
        "default_resolution = 456 #B5\n",
        "\n",
        "input_channels = 3\n",
        "depth_divisor= 8\n",
        "\n",
        "#dropout_rate = 0.2 #B0\n",
        "dropout_rate = 0.4 #B5\n",
        "\n",
        "drop_connect_rate = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8mbZ3f1-uIT"
      },
      "outputs": [],
      "source": [
        "kernel_size = [3,3,5,3,5,5,3]\n",
        "num_repeat = [1,2,2,3,3,4,1]\n",
        "output_filters = [16,24,40,80,112,192,320]\n",
        "strides = [1,2,2,2,1,2,1]\n",
        "MBConvBlock_1_True  =  [True,False,False,False,False,False,False]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyHbumNq-rQq"
      },
      "outputs": [],
      "source": [
        "def round_repeats(repeats, depth_coefficient):\n",
        "    return int(math.ceil(depth_coefficient * repeats))\n",
        "\n",
        "def round_filters(filters, width_coefficient, depth_divisor):\n",
        "    filters *= width_coefficient\n",
        "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
        "    new_filters = max(depth_divisor, new_filters)\n",
        "    if new_filters < 0.9 * filters:\n",
        "        new_filters += depth_divisor\n",
        "    return int(new_filters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUnY7GLj-3xJ"
      },
      "outputs": [],
      "source": [
        "# DropConnect 레이어 구현\n",
        "class DropConnect(layers.Layer):\n",
        "    def __init__(self, drop_connect_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.drop_connect_rate = drop_connect_rate\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        def _drop_connect():\n",
        "            keep_prob = 1.0 - self.drop_connect_rate\n",
        "\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            random_tensor = keep_prob\n",
        "            random_tensor += K.random_uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n",
        "            binary_tensor = tf.floor(random_tensor)\n",
        "            output = tf.math.divide(inputs, keep_prob) * binary_tensor\n",
        "            return output\n",
        "\n",
        "        return K.in_train_phase(_drop_connect, inputs, training=training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLfAxEt7-6xI"
      },
      "outputs": [],
      "source": [
        "#%% Squeeze-and-Excitation Block 함수 구현\n",
        "def SEBlock(filters,reduced_filters):\n",
        "    def _block(inputs):\n",
        "        x = layers.GlobalAveragePooling2D()(inputs)\n",
        "        x = layers.Reshape((1,1,x.shape[1]))(x)\n",
        "        x = layers.Conv2D(reduced_filters, 1, 1)(x)\n",
        "        x = tfa.activations.mish(x)\n",
        "        x = layers.Conv2D(filters, 1, 1)(x)\n",
        "        x = layers.Activation('sigmoid')(x)\n",
        "        x = layers.Multiply()([x, inputs])\n",
        "        return x\n",
        "    return _block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0TWt56W-89Y"
      },
      "outputs": [],
      "source": [
        "#%% MBConvBlock 함수 구현\n",
        "def MBConvBlock(x,kernel_size, strides,drop_connect_rate,output_channels,MBConvBlock_1_True=False):\n",
        "    output_channels = round_filters(output_channels,width_coefficient,depth_divisor)\n",
        "    if MBConvBlock_1_True:\n",
        "        block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(x)\n",
        "        block = layers.BatchNormalization()(block)\n",
        "        block = tfa.activations.mish(block)\n",
        "        block = SEBlock(x.shape[3],x.shape[3]/se_ratio)(block)\n",
        "        block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n",
        "        block = layers.BatchNormalization()(block)\n",
        "        return block\n",
        "\n",
        "    channels = x.shape[3]\n",
        "    expand_channels = channels * expand_ratio\n",
        "    block = layers.Conv2D(expand_channels, (1,1), padding='same', use_bias=False)(x)\n",
        "    block = layers.BatchNormalization()(block)\n",
        "    block = tfa.activations.mish(block)\n",
        "    block = layers.DepthwiseConv2D(kernel_size, strides,padding='same', use_bias=False)(block)\n",
        "    block = layers.BatchNormalization()(block)\n",
        "    block = tfa.activations.mish(block)\n",
        "    block = SEBlock(expand_channels,channels/se_ratio)(block)\n",
        "    block = layers.Conv2D(output_channels, (1,1), padding='same', use_bias=False)(block)\n",
        "    block = layers.BatchNormalization()(block)\n",
        "    if x.shape[3] == output_channels:\n",
        "        block = DropConnect(drop_connect_rate)(block)\n",
        "        block = layers.Add()([block, x])\n",
        "    return block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwZEGWju-_l-"
      },
      "outputs": [],
      "source": [
        "def EffNet(input_shape,num_classes):\n",
        "    x_input = layers.Input(shape=(default_resolution,default_resolution,input_channels))\n",
        "    x = layers.Conv2D(round_filters(32, width_coefficient, depth_divisor), (3,3), 2,padding='same', use_bias=False)(x_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tfa.activations.mish(x)\n",
        "    num_blocks_total = sum(num_repeat)\n",
        "    block_num = 0\n",
        "    for i in range(len(kernel_size)):\n",
        "        round_num_repeat = round_repeats(num_repeat[i], depth_coefficient)\n",
        "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
        "        x = MBConvBlock(x,kernel_size[i],strides[i],drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n",
        "        block_num += 1\n",
        "        if round_num_repeat > 1:\n",
        "            for bidx in range(round_num_repeat - 1):\n",
        "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
        "                x = MBConvBlock(x,kernel_size[i],1,drop_rate,output_filters[i],MBConvBlock_1_True = MBConvBlock_1_True[i])\n",
        "                block_num += 1\n",
        "    x = layers.Conv2D(round_filters(1280, width_coefficient, depth_divisor), 1,padding='same',use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tfa.activations.mish(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    x = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs=x_input, outputs=x)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCLkGIN_ELnr",
        "outputId": "195a721d-25c9-4ee8-dfb1-8fef21907de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 456, 456, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 228, 228, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 228, 228, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOpLamb  (None, 228, 228, 32  0          ['batch_normalization[0][0]']    \n",
            " da)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus (TFOpLambda)  (None, 228, 228, 32  0           ['tf.convert_to_tensor[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)      (None, 228, 228, 32  0           ['tf.math.softplus[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 228, 228, 32  0           ['tf.convert_to_tensor[0][0]',   \n",
            "                                )                                 'tf.math.tanh[0][0]']           \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 228, 228, 32  288        ['tf.math.multiply[0][0]']       \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 228, 228, 32  128        ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_1 (TFOpLa  (None, 228, 228, 32  0          ['batch_normalization_1[0][0]']  \n",
            " mbda)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_1 (TFOpLambda  (None, 228, 228, 32  0          ['tf.convert_to_tensor_1[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_1 (TFOpLambda)    (None, 228, 228, 32  0           ['tf.math.softplus_1[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, 228, 228, 32  0          ['tf.convert_to_tensor_1[0][0]', \n",
            " )                              )                                 'tf.math.tanh_1[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 32)          0           ['tf.math.multiply_1[0][0]']     \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 1, 32)     0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_2 (TFOpLa  (None, 1, 1, 8)     0           ['conv2d_1[0][0]']               \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_2 (TFOpLambda  (None, 1, 1, 8)     0           ['tf.convert_to_tensor_2[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_2 (TFOpLambda)    (None, 1, 1, 8)      0           ['tf.math.softplus_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, 1, 1, 8)     0           ['tf.convert_to_tensor_2[0][0]', \n",
            " )                                                                'tf.math.tanh_2[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['tf.math.multiply_2[0][0]']     \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 228, 228, 32  0           ['activation[0][0]',             \n",
            "                                )                                 'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 228, 228, 16  512         ['multiply[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 228, 228, 16  64         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 228, 228, 16  144        ['batch_normalization_2[0][0]']  \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 228, 228, 16  64         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_3 (TFOpLa  (None, 228, 228, 16  0          ['batch_normalization_3[0][0]']  \n",
            " mbda)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_3 (TFOpLambda  (None, 228, 228, 16  0          ['tf.convert_to_tensor_3[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_3 (TFOpLambda)    (None, 228, 228, 16  0           ['tf.math.softplus_3[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 228, 228, 16  0          ['tf.convert_to_tensor_3[0][0]', \n",
            " )                              )                                 'tf.math.tanh_3[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 16)          0           ['tf.math.multiply_3[0][0]']     \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 1, 1, 4)      68          ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_4 (TFOpLa  (None, 1, 1, 4)     0           ['conv2d_4[0][0]']               \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_4 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_4[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_4 (TFOpLambda)    (None, 1, 1, 4)      0           ['tf.math.softplus_4[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_4[0][0]', \n",
            " )                                                                'tf.math.tanh_4[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 16)     80          ['tf.math.multiply_4[0][0]']     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 16)     0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 228, 228, 16  0           ['activation_1[0][0]',           \n",
            "                                )                                 'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 228, 228, 16  256         ['multiply_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 228, 228, 16  64         ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 228, 228, 16  144        ['batch_normalization_4[0][0]']  \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 228, 228, 16  64         ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_5 (TFOpLa  (None, 228, 228, 16  0          ['batch_normalization_5[0][0]']  \n",
            " mbda)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_5 (TFOpLambda  (None, 228, 228, 16  0          ['tf.convert_to_tensor_5[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_5 (TFOpLambda)    (None, 228, 228, 16  0           ['tf.math.softplus_5[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None, 228, 228, 16  0          ['tf.convert_to_tensor_5[0][0]', \n",
            " )                              )                                 'tf.math.tanh_5[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 16)          0           ['tf.math.multiply_5[0][0]']     \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 1, 1, 4)      68          ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_6 (TFOpLa  (None, 1, 1, 4)     0           ['conv2d_7[0][0]']               \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_6 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_6[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_6 (TFOpLambda)    (None, 1, 1, 4)      0           ['tf.math.softplus_6[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_6[0][0]', \n",
            " )                                                                'tf.math.tanh_6[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 1, 1, 16)     80          ['tf.math.multiply_6[0][0]']     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 16)     0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 228, 228, 16  0           ['activation_2[0][0]',           \n",
            "                                )                                 'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 228, 228, 16  256         ['multiply_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 228, 228, 16  64         ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 228, 228, 96  1536        ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 228, 228, 96  384        ['conv2d_10[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_7 (TFOpLa  (None, 228, 228, 96  0          ['batch_normalization_7[0][0]']  \n",
            " mbda)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_7 (TFOpLambda  (None, 228, 228, 96  0          ['tf.convert_to_tensor_7[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_7 (TFOpLambda)    (None, 228, 228, 96  0           ['tf.math.softplus_7[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 228, 228, 96  0          ['tf.convert_to_tensor_7[0][0]', \n",
            " )                              )                                 'tf.math.tanh_7[0][0]']         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 114, 114, 96  864        ['tf.math.multiply_7[0][0]']     \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 114, 114, 96  384        ['depthwise_conv2d_3[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_8 (TFOpLa  (None, 114, 114, 96  0          ['batch_normalization_8[0][0]']  \n",
            " mbda)                          )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_8 (TFOpLambda  (None, 114, 114, 96  0          ['tf.convert_to_tensor_8[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_8 (TFOpLambda)    (None, 114, 114, 96  0           ['tf.math.softplus_8[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 114, 114, 96  0          ['tf.convert_to_tensor_8[0][0]', \n",
            " )                              )                                 'tf.math.tanh_8[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 96)          0           ['tf.math.multiply_8[0][0]']     \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 1, 1, 96)     0           ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 1, 1, 4)      388         ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_9 (TFOpLa  (None, 1, 1, 4)     0           ['conv2d_11[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_9 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_9[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_9 (TFOpLambda)    (None, 1, 1, 4)      0           ['tf.math.softplus_9[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 1, 1, 4)     0           ['tf.convert_to_tensor_9[0][0]', \n",
            " )                                                                'tf.math.tanh_9[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 1, 1, 96)     480         ['tf.math.multiply_9[0][0]']     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 96)     0           ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 114, 114, 96  0           ['activation_3[0][0]',           \n",
            "                                )                                 'tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 114, 114, 24  2304        ['multiply_3[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 114, 114, 24  96         ['conv2d_13[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 114, 114, 14  3456        ['batch_normalization_9[0][0]']  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 114, 114, 14  576        ['conv2d_14[0][0]']              \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_10 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_10[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_10 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_10[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_10 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_10[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_10[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_10[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 114, 114, 14  1296       ['tf.math.multiply_10[0][0]']    \n",
            " onv2D)                         4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 114, 114, 14  576        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_11 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_11[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_11 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_11[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_11 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_11[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_11[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_11[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4 (Gl  (None, 144)         0           ['tf.math.multiply_11[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 1, 144)    0           ['global_average_pooling2d_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 1, 1, 6)      870         ['reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_12 (TFOpL  (None, 1, 1, 6)     0           ['conv2d_15[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_12 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_12[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_12 (TFOpLambda)   (None, 1, 1, 6)      0           ['tf.math.softplus_12[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_12[0][0]',\n",
            " a)                                                               'tf.math.tanh_12[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 1, 1, 144)    1008        ['tf.math.multiply_12[0][0]']    \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 144)    0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 114, 114, 14  0           ['activation_4[0][0]',           \n",
            "                                4)                                'tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 114, 114, 24  3456        ['multiply_4[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 114, 114, 24  96         ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 114, 114, 24  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 114, 114, 24  0           ['drop_connect[0][0]',           \n",
            "                                )                                 'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 114, 114, 14  3456        ['add[0][0]']                    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 114, 114, 14  576        ['conv2d_18[0][0]']              \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_13 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_13[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_13 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_13[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_13 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_13[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_13[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_13[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 114, 114, 14  1296       ['tf.math.multiply_13[0][0]']    \n",
            " onv2D)                         4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 114, 114, 14  576        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_14 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_14[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_14 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_14[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_14 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_14[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_14 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_14[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_14[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5 (Gl  (None, 144)         0           ['tf.math.multiply_14[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1, 1, 144)    0           ['global_average_pooling2d_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 1, 1, 6)      870         ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_15 (TFOpL  (None, 1, 1, 6)     0           ['conv2d_19[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_15 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_15[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_15 (TFOpLambda)   (None, 1, 1, 6)      0           ['tf.math.softplus_15[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_15 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_15[0][0]',\n",
            " a)                                                               'tf.math.tanh_15[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 1, 1, 144)    1008        ['tf.math.multiply_15[0][0]']    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 144)    0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 114, 114, 14  0           ['activation_5[0][0]',           \n",
            "                                4)                                'tf.math.multiply_14[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 114, 114, 24  3456        ['multiply_5[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 114, 114, 24  96         ['conv2d_21[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 114, 114, 24  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 114, 114, 24  0           ['drop_connect_1[0][0]',         \n",
            "                                )                                 'add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 114, 114, 14  3456        ['add_1[0][0]']                  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 114, 114, 14  576        ['conv2d_22[0][0]']              \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_16 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_16[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_16 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_16[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_16 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_16[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_16 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_16[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_16[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 114, 114, 14  1296       ['tf.math.multiply_16[0][0]']    \n",
            " onv2D)                         4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 114, 114, 14  576        ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_17 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_17[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_17 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_17[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_17 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_17[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_17 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_17[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_17[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_6 (Gl  (None, 144)         0           ['tf.math.multiply_17[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 1, 144)    0           ['global_average_pooling2d_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 1, 1, 6)      870         ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_18 (TFOpL  (None, 1, 1, 6)     0           ['conv2d_23[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_18 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_18[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_18 (TFOpLambda)   (None, 1, 1, 6)      0           ['tf.math.softplus_18[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_18 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_18[0][0]',\n",
            " a)                                                               'tf.math.tanh_18[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 1, 1, 144)    1008        ['tf.math.multiply_18[0][0]']    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 144)    0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 114, 114, 14  0           ['activation_6[0][0]',           \n",
            "                                4)                                'tf.math.multiply_17[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 114, 114, 24  3456        ['multiply_6[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 114, 114, 24  96         ['conv2d_25[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 114, 114, 24  0           ['batch_normalization_18[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 114, 114, 24  0           ['drop_connect_2[0][0]',         \n",
            "                                )                                 'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 114, 114, 14  3456        ['add_2[0][0]']                  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 114, 114, 14  576        ['conv2d_26[0][0]']              \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_19 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_19[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_19 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_19[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_19 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_19[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_19 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_19[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_19[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 114, 114, 14  1296       ['tf.math.multiply_19[0][0]']    \n",
            " onv2D)                         4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 114, 114, 14  576        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_20 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_20[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_20 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_20[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_20 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_20[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_20 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_20[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_20[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_7 (Gl  (None, 144)         0           ['tf.math.multiply_20[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 1, 144)    0           ['global_average_pooling2d_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 1, 1, 6)      870         ['reshape_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_21 (TFOpL  (None, 1, 1, 6)     0           ['conv2d_27[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_21 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_21[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_21 (TFOpLambda)   (None, 1, 1, 6)      0           ['tf.math.softplus_21[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_21[0][0]',\n",
            " a)                                                               'tf.math.tanh_21[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 1, 1, 144)    1008        ['tf.math.multiply_21[0][0]']    \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 144)    0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 114, 114, 14  0           ['activation_7[0][0]',           \n",
            "                                4)                                'tf.math.multiply_20[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 114, 114, 24  3456        ['multiply_7[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 114, 114, 24  96         ['conv2d_29[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 114, 114, 24  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 114, 114, 24  0           ['drop_connect_3[0][0]',         \n",
            "                                )                                 'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 114, 114, 14  3456        ['add_3[0][0]']                  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 114, 114, 14  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_22 (TFOpL  (None, 114, 114, 14  0          ['batch_normalization_22[0][0]'] \n",
            " ambda)                         4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.softplus_22 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_22[0][0]']\n",
            " a)                             4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_22 (TFOpLambda)   (None, 114, 114, 14  0           ['tf.math.softplus_22[0][0]']    \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  (None, 114, 114, 14  0          ['tf.convert_to_tensor_22[0][0]',\n",
            " a)                             4)                                'tf.math.tanh_22[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 57, 57, 144)  3600       ['tf.math.multiply_22[0][0]']    \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 57, 57, 144)  576        ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_23 (TFOpL  (None, 57, 57, 144)  0          ['batch_normalization_23[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_23 (TFOpLambd  (None, 57, 57, 144)  0          ['tf.convert_to_tensor_23[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_23 (TFOpLambda)   (None, 57, 57, 144)  0           ['tf.math.softplus_23[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  (None, 57, 57, 144)  0          ['tf.convert_to_tensor_23[0][0]',\n",
            " a)                                                               'tf.math.tanh_23[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8 (Gl  (None, 144)         0           ['tf.math.multiply_23[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 1, 1, 144)    0           ['global_average_pooling2d_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 1, 1, 6)      870         ['reshape_8[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_24 (TFOpL  (None, 1, 1, 6)     0           ['conv2d_31[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_24 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_24[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_24 (TFOpLambda)   (None, 1, 1, 6)      0           ['tf.math.softplus_24[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_24 (TFOpLambd  (None, 1, 1, 6)     0           ['tf.convert_to_tensor_24[0][0]',\n",
            " a)                                                               'tf.math.tanh_24[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 1, 1, 144)    1008        ['tf.math.multiply_24[0][0]']    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 144)    0           ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 57, 57, 144)  0           ['activation_8[0][0]',           \n",
            "                                                                  'tf.math.multiply_23[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 57, 57, 40)   5760        ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 57, 57, 40)  160         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 57, 57, 240)  9600        ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 57, 57, 240)  960        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_25 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_25[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_25 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_25[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_25 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_25[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_25 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_25[0][0]',\n",
            " a)                                                               'tf.math.tanh_25[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 57, 57, 240)  6000       ['tf.math.multiply_25[0][0]']    \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 57, 57, 240)  960        ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_26 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_26[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_26 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_26[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_26 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_26[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_26 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_26[0][0]',\n",
            " a)                                                               'tf.math.tanh_26[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9 (Gl  (None, 240)         0           ['tf.math.multiply_26[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)            (None, 1, 1, 240)    0           ['global_average_pooling2d_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 1, 1, 10)     2410        ['reshape_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_27 (TFOpL  (None, 1, 1, 10)    0           ['conv2d_35[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_27 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_27[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_27 (TFOpLambda)   (None, 1, 1, 10)     0           ['tf.math.softplus_27[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_27 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_27[0][0]',\n",
            " a)                                                               'tf.math.tanh_27[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 1, 1, 240)    2640        ['tf.math.multiply_27[0][0]']    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 240)    0           ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 57, 57, 240)  0           ['activation_9[0][0]',           \n",
            "                                                                  'tf.math.multiply_26[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 57, 57, 40)   9600        ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 57, 57, 40)  160         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 57, 57, 40)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 57, 57, 40)   0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 57, 57, 240)  9600        ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 57, 57, 240)  960        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_28 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_28[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_28 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_28[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_28 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_28[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_28 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_28[0][0]',\n",
            " a)                                                               'tf.math.tanh_28[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 57, 57, 240)  6000       ['tf.math.multiply_28[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 57, 57, 240)  960        ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_29 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_29[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_29 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_29[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_29 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_29[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_29 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_29[0][0]',\n",
            " a)                                                               'tf.math.tanh_29[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_10 (G  (None, 240)         0           ['tf.math.multiply_29[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)           (None, 1, 1, 240)    0           ['global_average_pooling2d_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 1, 1, 10)     2410        ['reshape_10[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_30 (TFOpL  (None, 1, 1, 10)    0           ['conv2d_39[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_30 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_30[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_30 (TFOpLambda)   (None, 1, 1, 10)     0           ['tf.math.softplus_30[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_30 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_30[0][0]',\n",
            " a)                                                               'tf.math.tanh_30[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 1, 1, 240)    2640        ['tf.math.multiply_30[0][0]']    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 240)    0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 57, 57, 240)  0           ['activation_10[0][0]',          \n",
            "                                                                  'tf.math.multiply_29[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 57, 57, 40)   9600        ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 57, 57, 40)  160         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 57, 57, 40)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 57, 57, 40)   0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 57, 57, 240)  9600        ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 57, 57, 240)  960        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_31 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_31[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_31 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_31[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_31 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_31[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_31 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_31[0][0]',\n",
            " a)                                                               'tf.math.tanh_31[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 57, 57, 240)  6000       ['tf.math.multiply_31[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 57, 57, 240)  960        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_32 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_32[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_32 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_32[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_32 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_32[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_32 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_32[0][0]',\n",
            " a)                                                               'tf.math.tanh_32[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_11 (G  (None, 240)         0           ['tf.math.multiply_32[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 1, 1, 240)    0           ['global_average_pooling2d_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 1, 1, 10)     2410        ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_33 (TFOpL  (None, 1, 1, 10)    0           ['conv2d_43[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_33 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_33[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_33 (TFOpLambda)   (None, 1, 1, 10)     0           ['tf.math.softplus_33[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_33 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_33[0][0]',\n",
            " a)                                                               'tf.math.tanh_33[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 1, 1, 240)    2640        ['tf.math.multiply_33[0][0]']    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 240)    0           ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 57, 57, 240)  0           ['activation_11[0][0]',          \n",
            "                                                                  'tf.math.multiply_32[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 57, 57, 40)   9600        ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 57, 57, 40)  160         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 57, 57, 40)   0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 57, 57, 40)   0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 57, 57, 240)  9600        ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 57, 57, 240)  960        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_34 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_34[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_34 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_34[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_34 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_34[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_34 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_34[0][0]',\n",
            " a)                                                               'tf.math.tanh_34[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 57, 57, 240)  6000       ['tf.math.multiply_34[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 57, 57, 240)  960        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_35 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_35[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_35 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_35[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_35 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_35[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_35 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_35[0][0]',\n",
            " a)                                                               'tf.math.tanh_35[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_12 (G  (None, 240)         0           ['tf.math.multiply_35[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 1, 240)    0           ['global_average_pooling2d_12[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 1, 1, 10)     2410        ['reshape_12[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_36 (TFOpL  (None, 1, 1, 10)    0           ['conv2d_47[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_36 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_36[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_36 (TFOpLambda)   (None, 1, 1, 10)     0           ['tf.math.softplus_36[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_36 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_36[0][0]',\n",
            " a)                                                               'tf.math.tanh_36[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 1, 1, 240)    2640        ['tf.math.multiply_36[0][0]']    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 240)    0           ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 57, 57, 240)  0           ['activation_12[0][0]',          \n",
            "                                                                  'tf.math.multiply_35[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 57, 57, 40)   9600        ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 57, 57, 40)  160         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 57, 57, 40)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 57, 57, 40)   0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 57, 57, 240)  9600        ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 57, 57, 240)  960        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_37 (TFOpL  (None, 57, 57, 240)  0          ['batch_normalization_37[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_37 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_37[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_37 (TFOpLambda)   (None, 57, 57, 240)  0           ['tf.math.softplus_37[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_37 (TFOpLambd  (None, 57, 57, 240)  0          ['tf.convert_to_tensor_37[0][0]',\n",
            " a)                                                               'tf.math.tanh_37[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 29, 29, 240)  2160       ['tf.math.multiply_37[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 29, 29, 240)  960        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_38 (TFOpL  (None, 29, 29, 240)  0          ['batch_normalization_38[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_38 (TFOpLambd  (None, 29, 29, 240)  0          ['tf.convert_to_tensor_38[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_38 (TFOpLambda)   (None, 29, 29, 240)  0           ['tf.math.softplus_38[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_38 (TFOpLambd  (None, 29, 29, 240)  0          ['tf.convert_to_tensor_38[0][0]',\n",
            " a)                                                               'tf.math.tanh_38[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_13 (G  (None, 240)         0           ['tf.math.multiply_38[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 1, 1, 240)    0           ['global_average_pooling2d_13[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 1, 1, 10)     2410        ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_39 (TFOpL  (None, 1, 1, 10)    0           ['conv2d_51[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_39 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_39[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_39 (TFOpLambda)   (None, 1, 1, 10)     0           ['tf.math.softplus_39[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_39 (TFOpLambd  (None, 1, 1, 10)    0           ['tf.convert_to_tensor_39[0][0]',\n",
            " a)                                                               'tf.math.tanh_39[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 1, 1, 240)    2640        ['tf.math.multiply_39[0][0]']    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 240)    0           ['conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 29, 29, 240)  0           ['activation_13[0][0]',          \n",
            "                                                                  'tf.math.multiply_38[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 29, 29, 80)   19200       ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 29, 29, 80)  320         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 29, 29, 480)  38400       ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_40 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_40[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_40 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_40[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_40 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_40[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_40 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_40[0][0]',\n",
            " a)                                                               'tf.math.tanh_40[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_40[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_41 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_41[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_41 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_41[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_41 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_41[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_41 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_41[0][0]',\n",
            " a)                                                               'tf.math.tanh_41[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_14 (G  (None, 480)         0           ['tf.math.multiply_41[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_14[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_42 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_55[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_42 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_42[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_42 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_42[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_42 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_42[0][0]',\n",
            " a)                                                               'tf.math.tanh_42[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_42[0][0]']    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 480)    0           ['conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 29, 29, 480)  0           ['activation_14[0][0]',          \n",
            "                                                                  'tf.math.multiply_41[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 29, 29, 80)  320         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 29, 29, 80)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 29, 29, 80)   0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 29, 29, 480)  38400       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_43 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_43[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_43 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_43[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_43 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_43[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_43 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_43[0][0]',\n",
            " a)                                                               'tf.math.tanh_43[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_43[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_44 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_44[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_44 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_44[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_44 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_44[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_44 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_44[0][0]',\n",
            " a)                                                               'tf.math.tanh_44[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_15 (G  (None, 480)         0           ['tf.math.multiply_44[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_15 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_15[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_45 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_59[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_45 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_45[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_45 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_45[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_45 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_45[0][0]',\n",
            " a)                                                               'tf.math.tanh_45[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_45[0][0]']    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 480)    0           ['conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 29, 29, 480)  0           ['activation_15[0][0]',          \n",
            "                                                                  'tf.math.multiply_44[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 29, 29, 80)  320         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 29, 29, 80)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 29, 29, 80)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 29, 29, 480)  38400       ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_46 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_46[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_46 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_46[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_46 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_46[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_46 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_46[0][0]',\n",
            " a)                                                               'tf.math.tanh_46[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_46[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_47 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_47[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_47 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_47[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_47 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_47[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_47 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_47[0][0]',\n",
            " a)                                                               'tf.math.tanh_47[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_16 (G  (None, 480)         0           ['tf.math.multiply_47[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_16 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_16[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_16[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_48 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_63[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_48 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_48[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_48 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_48[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_48 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_48[0][0]',\n",
            " a)                                                               'tf.math.tanh_48[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_48[0][0]']    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 480)    0           ['conv2d_64[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 29, 29, 480)  0           ['activation_16[0][0]',          \n",
            "                                                                  'tf.math.multiply_47[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 29, 29, 80)  320         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 29, 29, 80)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 29, 29, 80)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 29, 29, 480)  38400       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_49 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_49[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_49 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_49[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_49 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_49[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_49 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_49[0][0]',\n",
            " a)                                                               'tf.math.tanh_49[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_49[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_50 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_50[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_50 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_50[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_50 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_50[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_50 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_50[0][0]',\n",
            " a)                                                               'tf.math.tanh_50[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_17 (G  (None, 480)         0           ['tf.math.multiply_50[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_17 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_17[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_51 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_67[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_51 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_51[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_51 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_51[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_51 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_51[0][0]',\n",
            " a)                                                               'tf.math.tanh_51[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_51[0][0]']    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 480)    0           ['conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 29, 29, 480)  0           ['activation_17[0][0]',          \n",
            "                                                                  'tf.math.multiply_50[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 29, 29, 80)  320         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 29, 29, 80)   0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 29, 29, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 29, 29, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_52 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_52[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_52 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_52[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_52 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_52[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_52 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_52[0][0]',\n",
            " a)                                                               'tf.math.tanh_52[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_52[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_53 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_53[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_53 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_53[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_53 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_53[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_53 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_53[0][0]',\n",
            " a)                                                               'tf.math.tanh_53[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_18 (G  (None, 480)         0           ['tf.math.multiply_53[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_18[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_18[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_54 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_71[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_54 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_54[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_54 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_54[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_54 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_54[0][0]',\n",
            " a)                                                               'tf.math.tanh_54[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_54[0][0]']    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 480)    0           ['conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 29, 29, 480)  0           ['activation_18[0][0]',          \n",
            "                                                                  'tf.math.multiply_53[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 29, 29, 80)  320         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 29, 29, 80)   0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 29, 29, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 29, 29, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_55 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_55[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_55 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_55[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_55 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_55[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_55 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_55[0][0]',\n",
            " a)                                                               'tf.math.tanh_55[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 29, 29, 480)  4320       ['tf.math.multiply_55[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_56 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_56[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_56 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_56[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_56 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_56[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_56 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_56[0][0]',\n",
            " a)                                                               'tf.math.tanh_56[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_19 (G  (None, 480)         0           ['tf.math.multiply_56[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_19[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_19[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_57 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_75[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_57 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_57[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_57 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_57[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_57 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_57[0][0]',\n",
            " a)                                                               'tf.math.tanh_57[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_57[0][0]']    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 480)    0           ['conv2d_76[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 29, 29, 480)  0           ['activation_19[0][0]',          \n",
            "                                                                  'tf.math.multiply_56[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 29, 29, 80)   38400       ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 29, 29, 80)  320         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 29, 29, 80)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 29, 29, 80)   0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 29, 29, 480)  38400       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 29, 29, 480)  1920       ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_58 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_58[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_58 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_58[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_58 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_58[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_58 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_58[0][0]',\n",
            " a)                                                               'tf.math.tanh_58[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 29, 29, 480)  12000      ['tf.math.multiply_58[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 29, 29, 480)  1920       ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_59 (TFOpL  (None, 29, 29, 480)  0          ['batch_normalization_59[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_59 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_59[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_59 (TFOpLambda)   (None, 29, 29, 480)  0           ['tf.math.softplus_59[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_59 (TFOpLambd  (None, 29, 29, 480)  0          ['tf.convert_to_tensor_59[0][0]',\n",
            " a)                                                               'tf.math.tanh_59[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_20 (G  (None, 480)         0           ['tf.math.multiply_59[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_20 (Reshape)           (None, 1, 1, 480)    0           ['global_average_pooling2d_20[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 20)     9620        ['reshape_20[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_60 (TFOpL  (None, 1, 1, 20)    0           ['conv2d_79[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_60 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_60[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_60 (TFOpLambda)   (None, 1, 1, 20)     0           ['tf.math.softplus_60[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_60 (TFOpLambd  (None, 1, 1, 20)    0           ['tf.convert_to_tensor_60[0][0]',\n",
            " a)                                                               'tf.math.tanh_60[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 1, 1, 480)    10080       ['tf.math.multiply_60[0][0]']    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 480)    0           ['conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 29, 29, 480)  0           ['activation_20[0][0]',          \n",
            "                                                                  'tf.math.multiply_59[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 29, 29, 112)  53760       ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 29, 29, 112)  448        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 29, 29, 672)  75264       ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_61 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_61[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_61 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_61[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_61 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_61[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_61 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_61[0][0]',\n",
            " a)                                                               'tf.math.tanh_61[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_61[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_62 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_62[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_62 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_62[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_62 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_62[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_62 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_62[0][0]',\n",
            " a)                                                               'tf.math.tanh_62[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_21 (G  (None, 672)         0           ['tf.math.multiply_62[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_21 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_21[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 28)     18844       ['reshape_21[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_63 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_83[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_63 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_63[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_63 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_63[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_63 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_63[0][0]',\n",
            " a)                                                               'tf.math.tanh_63[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 1, 1, 672)    19488       ['tf.math.multiply_63[0][0]']    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 672)    0           ['conv2d_84[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 29, 29, 672)  0           ['activation_21[0][0]',          \n",
            "                                                                  'tf.math.multiply_62[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 29, 29, 112)  75264       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 29, 29, 112)  448        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 29, 29, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_64 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_64[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_64 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_64[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_64 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_64[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_64 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_64[0][0]',\n",
            " a)                                                               'tf.math.tanh_64[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_64[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_65 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_65[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_65 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_65[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_65 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_65[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_65 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_65[0][0]',\n",
            " a)                                                               'tf.math.tanh_65[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_22 (G  (None, 672)         0           ['tf.math.multiply_65[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_22 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_22[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 28)     18844       ['reshape_22[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_66 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_87[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_66 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_66[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_66 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_66[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_66 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_66[0][0]',\n",
            " a)                                                               'tf.math.tanh_66[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 1, 1, 672)    19488       ['tf.math.multiply_66[0][0]']    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 672)    0           ['conv2d_88[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 29, 29, 672)  0           ['activation_22[0][0]',          \n",
            "                                                                  'tf.math.multiply_65[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 29, 29, 112)  75264       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 29, 29, 112)  448        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 29, 29, 672)  75264       ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_67 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_67[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_67 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_67[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_67 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_67[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_67 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_67[0][0]',\n",
            " a)                                                               'tf.math.tanh_67[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_67[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_68 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_68[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_68 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_68[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_68 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_68[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_68 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_68[0][0]',\n",
            " a)                                                               'tf.math.tanh_68[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_23 (G  (None, 672)         0           ['tf.math.multiply_68[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_23 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_23[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 28)     18844       ['reshape_23[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_69 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_91[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_69 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_69[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_69 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_69[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_69 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_69[0][0]',\n",
            " a)                                                               'tf.math.tanh_69[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 1, 1, 672)    19488       ['tf.math.multiply_69[0][0]']    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 672)    0           ['conv2d_92[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 29, 29, 672)  0           ['activation_23[0][0]',          \n",
            "                                                                  'tf.math.multiply_68[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 29, 29, 112)  75264       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 29, 29, 112)  448        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 29, 29, 672)  75264       ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_70 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_70[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_70 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_70[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_70 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_70[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_70 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_70[0][0]',\n",
            " a)                                                               'tf.math.tanh_70[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_70[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_71 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_71[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_71 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_71[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_71 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_71[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_71 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_71[0][0]',\n",
            " a)                                                               'tf.math.tanh_71[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_24 (G  (None, 672)         0           ['tf.math.multiply_71[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_24 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_24[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 28)     18844       ['reshape_24[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_72 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_95[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_72 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_72[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_72 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_72[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_72 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_72[0][0]',\n",
            " a)                                                               'tf.math.tanh_72[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 1, 1, 672)    19488       ['tf.math.multiply_72[0][0]']    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 672)    0           ['conv2d_96[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 29, 29, 672)  0           ['activation_24[0][0]',          \n",
            "                                                                  'tf.math.multiply_71[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 29, 29, 112)  75264       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 29, 29, 112)  448        ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 29, 29, 672)  75264       ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_73 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_73[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_73 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_73[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_73 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_73[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_73 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_73[0][0]',\n",
            " a)                                                               'tf.math.tanh_73[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_73[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_74 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_74[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_74 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_74[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_74 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_74[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_74 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_74[0][0]',\n",
            " a)                                                               'tf.math.tanh_74[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_25 (G  (None, 672)         0           ['tf.math.multiply_74[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_25 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_25[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 28)     18844       ['reshape_25[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_75 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_99[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_75 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_75[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_75 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_75[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_75 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_75[0][0]',\n",
            " a)                                                               'tf.math.tanh_75[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 1, 1, 672)    19488       ['tf.math.multiply_75[0][0]']    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_100[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 29, 29, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'tf.math.multiply_74[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 29, 29, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 29, 29, 112)  448        ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_18 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_18[0][0]',        \n",
            "                                                                  'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 29, 29, 672)  75264       ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_102[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_76 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_76[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_76 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_76[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_76 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_76[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_76 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_76[0][0]',\n",
            " a)                                                               'tf.math.tanh_76[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 29, 29, 672)  16800      ['tf.math.multiply_76[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 29, 29, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_77 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_77[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_77 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_77[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_77 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_77[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_77 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_77[0][0]',\n",
            " a)                                                               'tf.math.tanh_77[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_26 (G  (None, 672)         0           ['tf.math.multiply_77[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_26 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_26[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 28)     18844       ['reshape_26[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_78 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_103[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_78 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_78[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_78 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_78[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_78 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_78[0][0]',\n",
            " a)                                                               'tf.math.tanh_78[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 1, 1, 672)    19488       ['tf.math.multiply_78[0][0]']    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_104[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 29, 29, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'tf.math.multiply_77[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 29, 29, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 29, 29, 112)  448        ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_19 (DropConnect)  (None, 29, 29, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 29, 29, 112)  0           ['drop_connect_19[0][0]',        \n",
            "                                                                  'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 29, 29, 672)  75264       ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 29, 29, 672)  2688       ['conv2d_106[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_79 (TFOpL  (None, 29, 29, 672)  0          ['batch_normalization_79[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_79 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_79[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_79 (TFOpLambda)   (None, 29, 29, 672)  0           ['tf.math.softplus_79[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_79 (TFOpLambd  (None, 29, 29, 672)  0          ['tf.convert_to_tensor_79[0][0]',\n",
            " a)                                                               'tf.math.tanh_79[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 15, 15, 672)  16800      ['tf.math.multiply_79[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 15, 15, 672)  2688       ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_80 (TFOpL  (None, 15, 15, 672)  0          ['batch_normalization_80[0][0]'] \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_80 (TFOpLambd  (None, 15, 15, 672)  0          ['tf.convert_to_tensor_80[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_80 (TFOpLambda)   (None, 15, 15, 672)  0           ['tf.math.softplus_80[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_80 (TFOpLambd  (None, 15, 15, 672)  0          ['tf.convert_to_tensor_80[0][0]',\n",
            " a)                                                               'tf.math.tanh_80[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_27 (G  (None, 672)         0           ['tf.math.multiply_80[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_27 (Reshape)           (None, 1, 1, 672)    0           ['global_average_pooling2d_27[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 28)     18844       ['reshape_27[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_81 (TFOpL  (None, 1, 1, 28)    0           ['conv2d_107[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_81 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_81[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_81 (TFOpLambda)   (None, 1, 1, 28)     0           ['tf.math.softplus_81[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_81 (TFOpLambd  (None, 1, 1, 28)    0           ['tf.convert_to_tensor_81[0][0]',\n",
            " a)                                                               'tf.math.tanh_81[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 1, 1, 672)    19488       ['tf.math.multiply_81[0][0]']    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_108[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 15, 15, 672)  0           ['activation_27[0][0]',          \n",
            "                                                                  'tf.math.multiply_80[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 15, 15, 192)  129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 15, 15, 192)  768        ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 15, 15, 1152  221184      ['batch_normalization_81[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_110[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_82 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_82[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_82 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_82[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_82 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_82[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_82 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_82[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_82[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_82[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_83 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_83[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_83 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_83[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_83 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_83[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_83 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_83[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_83[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_28 (G  (None, 1152)        0           ['tf.math.multiply_83[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_28 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_28[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_28[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_84 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_111[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_84 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_84[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_84 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_84[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_84 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_84[0][0]',\n",
            " a)                                                               'tf.math.tanh_84[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_84[0][0]']    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_112[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 15, 15, 1152  0           ['activation_28[0][0]',          \n",
            "                                )                                 'tf.math.multiply_83[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 15, 15, 192)  768        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_20 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_20[0][0]',        \n",
            "                                                                  'batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 15, 15, 1152  221184      ['add_20[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_114[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_85 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_85[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_85 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_85[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_85 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_85[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_85 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_85[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_85[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_85[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_86 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_86[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_86 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_86[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_86 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_86[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_86 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_86[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_86[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_29 (G  (None, 1152)        0           ['tf.math.multiply_86[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_29 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_29[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_29[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_87 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_115[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_87 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_87[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_87 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_87[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_87 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_87[0][0]',\n",
            " a)                                                               'tf.math.tanh_87[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_87[0][0]']    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_116[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 15, 15, 1152  0           ['activation_29[0][0]',          \n",
            "                                )                                 'tf.math.multiply_86[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 15, 15, 192)  768        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_21 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_21[0][0]',        \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 15, 15, 1152  221184      ['add_21[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_118[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_88 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_88[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_88 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_88[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_88 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_88[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_88 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_88[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_88[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_88[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_89 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_89[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_89 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_89[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_89 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_89[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_89 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_89[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_89[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_30 (G  (None, 1152)        0           ['tf.math.multiply_89[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_30 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_30[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_30[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_90 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_119[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_90 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_90[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_90 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_90[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_90 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_90[0][0]',\n",
            " a)                                                               'tf.math.tanh_90[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_90[0][0]']    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_120[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 15, 15, 1152  0           ['activation_30[0][0]',          \n",
            "                                )                                 'tf.math.multiply_89[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 15, 15, 192)  768        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_22 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_22[0][0]',        \n",
            "                                                                  'add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 15, 15, 1152  221184      ['add_22[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_122[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_91 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_91[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_91 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_91[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_91 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_91[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_91 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_91[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_91[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_91[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_92 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_92[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_92 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_92[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_92 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_92[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_92 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_92[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_92[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_31 (G  (None, 1152)        0           ['tf.math.multiply_92[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_31 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_31[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_31[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_93 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_123[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_93 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_93[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_93 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_93[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_93 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_93[0][0]',\n",
            " a)                                                               'tf.math.tanh_93[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_93[0][0]']    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_124[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 15, 15, 1152  0           ['activation_31[0][0]',          \n",
            "                                )                                 'tf.math.multiply_92[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 15, 15, 192)  768        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_23 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_23[0][0]',        \n",
            "                                                                  'add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 15, 15, 1152  221184      ['add_23[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_126[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_94 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_94[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_94 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_94[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_94 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_94[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_94 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_94[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_94[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_32 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_94[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_32[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_95 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_95[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_95 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_95[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_95 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_95[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_95 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_95[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_95[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_32 (G  (None, 1152)        0           ['tf.math.multiply_95[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_32 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_32[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_32[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_96 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_127[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_96 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_96[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_96 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_96[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_96 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_96[0][0]',\n",
            " a)                                                               'tf.math.tanh_96[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_96[0][0]']    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_128[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_32 (Multiply)         (None, 15, 15, 1152  0           ['activation_32[0][0]',          \n",
            "                                )                                 'tf.math.multiply_95[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_32[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 15, 15, 192)  768        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_24 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_24[0][0]',        \n",
            "                                                                  'add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 15, 15, 1152  221184      ['add_24[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 15, 15, 1152  4608       ['conv2d_130[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_97 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_97[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_97 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_97[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_97 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_97[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_97 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_97[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_97[0][0]']        \n",
            "                                                                                                  \n",
            " depthwise_conv2d_33 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_97[0][0]']    \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 15, 15, 1152  4608       ['depthwise_conv2d_33[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_98 (TFOpL  (None, 15, 15, 1152  0          ['batch_normalization_98[0][0]'] \n",
            " ambda)                         )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_98 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_98[0][0]']\n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_98 (TFOpLambda)   (None, 15, 15, 1152  0           ['tf.math.softplus_98[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_98 (TFOpLambd  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_98[0][0]',\n",
            " a)                             )                                 'tf.math.tanh_98[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_33 (G  (None, 1152)        0           ['tf.math.multiply_98[0][0]']    \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_33 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_33[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_99 (TFOpL  (None, 1, 1, 48)    0           ['conv2d_131[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.softplus_99 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_99[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.tanh_99 (TFOpLambda)   (None, 1, 1, 48)     0           ['tf.math.softplus_99[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_99 (TFOpLambd  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_99[0][0]',\n",
            " a)                                                               'tf.math.tanh_99[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_99[0][0]']    \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_132[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_33 (Multiply)         (None, 15, 15, 1152  0           ['activation_33[0][0]',          \n",
            "                                )                                 'tf.math.multiply_98[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_33[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 15, 15, 192)  768        ['conv2d_133[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_25 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_25[0][0]',        \n",
            "                                                                  'add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 15, 15, 1152  221184      ['add_25[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 15, 15, 1152  4608       ['conv2d_134[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_100 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_100[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_100 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_100[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_100 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_100[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_100 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_100[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_100[0][0]']      \n",
            "                                                                                                  \n",
            " depthwise_conv2d_34 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_100[0][0]']   \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 15, 15, 1152  4608       ['depthwise_conv2d_34[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_101 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_101[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_101 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_101[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_101 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_101[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_101 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_101[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_101[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_34 (G  (None, 1152)        0           ['tf.math.multiply_101[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_34 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_34[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_34[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_102 (TFOp  (None, 1, 1, 48)    0           ['conv2d_135[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.softplus_102 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_102[0][0]'\n",
            " da)                                                             ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_102 (TFOpLambda)  (None, 1, 1, 48)     0           ['tf.math.softplus_102[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_102 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_102[0][0]'\n",
            " da)                                                             , 'tf.math.tanh_102[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_102[0][0]']   \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_136[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_34 (Multiply)         (None, 15, 15, 1152  0           ['activation_34[0][0]',          \n",
            "                                )                                 'tf.math.multiply_101[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_34[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 15, 15, 192)  768        ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_26 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_26[0][0]',        \n",
            "                                                                  'add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 15, 15, 1152  221184      ['add_26[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 15, 15, 1152  4608       ['conv2d_138[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_103 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_103[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_103 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_103[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_103 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_103[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_103 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_103[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_103[0][0]']      \n",
            "                                                                                                  \n",
            " depthwise_conv2d_35 (Depthwise  (None, 15, 15, 1152  28800      ['tf.math.multiply_103[0][0]']   \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 15, 15, 1152  4608       ['depthwise_conv2d_35[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_104 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_104[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_104 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_104[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_104 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_104[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_104 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_104[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_104[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_35 (G  (None, 1152)        0           ['tf.math.multiply_104[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_35 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_35[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_35[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_105 (TFOp  (None, 1, 1, 48)    0           ['conv2d_139[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.softplus_105 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_105[0][0]'\n",
            " da)                                                             ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_105 (TFOpLambda)  (None, 1, 1, 48)     0           ['tf.math.softplus_105[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_105 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_105[0][0]'\n",
            " da)                                                             , 'tf.math.tanh_105[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_105[0][0]']   \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_140[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_35 (Multiply)         (None, 15, 15, 1152  0           ['activation_35[0][0]',          \n",
            "                                )                                 'tf.math.multiply_104[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 15, 15, 192)  221184      ['multiply_35[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 15, 15, 192)  768        ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_27 (DropConnect)  (None, 15, 15, 192)  0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 15, 15, 192)  0           ['drop_connect_27[0][0]',        \n",
            "                                                                  'add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 15, 15, 1152  221184      ['add_27[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 15, 15, 1152  4608       ['conv2d_142[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_106 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_106[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_106 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_106[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_106 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_106[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_106 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_106[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_106[0][0]']      \n",
            "                                                                                                  \n",
            " depthwise_conv2d_36 (Depthwise  (None, 15, 15, 1152  10368      ['tf.math.multiply_106[0][0]']   \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 15, 15, 1152  4608       ['depthwise_conv2d_36[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_107 (TFOp  (None, 15, 15, 1152  0          ['batch_normalization_107[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_107 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_107[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_107 (TFOpLambda)  (None, 15, 15, 1152  0           ['tf.math.softplus_107[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_107 (TFOpLamb  (None, 15, 15, 1152  0          ['tf.convert_to_tensor_107[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_107[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_36 (G  (None, 1152)        0           ['tf.math.multiply_107[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_36 (Reshape)           (None, 1, 1, 1152)   0           ['global_average_pooling2d_36[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 1, 1, 48)     55344       ['reshape_36[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_108 (TFOp  (None, 1, 1, 48)    0           ['conv2d_143[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.softplus_108 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_108[0][0]'\n",
            " da)                                                             ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_108 (TFOpLambda)  (None, 1, 1, 48)     0           ['tf.math.softplus_108[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_108 (TFOpLamb  (None, 1, 1, 48)    0           ['tf.convert_to_tensor_108[0][0]'\n",
            " da)                                                             , 'tf.math.tanh_108[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 1, 1, 1152)   56448       ['tf.math.multiply_108[0][0]']   \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_144[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_36 (Multiply)         (None, 15, 15, 1152  0           ['activation_36[0][0]',          \n",
            "                                )                                 'tf.math.multiply_107[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 15, 15, 320)  368640      ['multiply_36[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 15, 15, 320)  1280       ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 15, 15, 1920  614400      ['batch_normalization_108[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 15, 15, 1920  7680       ['conv2d_146[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_109 (TFOp  (None, 15, 15, 1920  0          ['batch_normalization_109[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_109 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_109[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_109 (TFOpLambda)  (None, 15, 15, 1920  0           ['tf.math.softplus_109[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_109 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_109[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_109[0][0]']      \n",
            "                                                                                                  \n",
            " depthwise_conv2d_37 (Depthwise  (None, 15, 15, 1920  17280      ['tf.math.multiply_109[0][0]']   \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 15, 15, 1920  7680       ['depthwise_conv2d_37[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_110 (TFOp  (None, 15, 15, 1920  0          ['batch_normalization_110[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_110 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_110[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_110 (TFOpLambda)  (None, 15, 15, 1920  0           ['tf.math.softplus_110[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_110 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_110[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_110[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_37 (G  (None, 1920)        0           ['tf.math.multiply_110[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_37 (Reshape)           (None, 1, 1, 1920)   0           ['global_average_pooling2d_37[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 1, 1, 80)     153680      ['reshape_37[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_111 (TFOp  (None, 1, 1, 80)    0           ['conv2d_147[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.softplus_111 (TFOpLamb  (None, 1, 1, 80)    0           ['tf.convert_to_tensor_111[0][0]'\n",
            " da)                                                             ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_111 (TFOpLambda)  (None, 1, 1, 80)     0           ['tf.math.softplus_111[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_111 (TFOpLamb  (None, 1, 1, 80)    0           ['tf.convert_to_tensor_111[0][0]'\n",
            " da)                                                             , 'tf.math.tanh_111[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 1, 1, 1920)   155520      ['tf.math.multiply_111[0][0]']   \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 1, 1, 1920)   0           ['conv2d_148[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_37 (Multiply)         (None, 15, 15, 1920  0           ['activation_37[0][0]',          \n",
            "                                )                                 'tf.math.multiply_110[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 15, 15, 320)  614400      ['multiply_37[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 15, 15, 320)  1280       ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_28 (DropConnect)  (None, 15, 15, 320)  0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 15, 15, 320)  0           ['drop_connect_28[0][0]',        \n",
            "                                                                  'batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 15, 15, 1920  614400      ['add_28[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 15, 15, 1920  7680       ['conv2d_150[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_112 (TFOp  (None, 15, 15, 1920  0          ['batch_normalization_112[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_112 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_112[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_112 (TFOpLambda)  (None, 15, 15, 1920  0           ['tf.math.softplus_112[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_112 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_112[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_112[0][0]']      \n",
            "                                                                                                  \n",
            " depthwise_conv2d_38 (Depthwise  (None, 15, 15, 1920  17280      ['tf.math.multiply_112[0][0]']   \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 15, 15, 1920  7680       ['depthwise_conv2d_38[0][0]']    \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_113 (TFOp  (None, 15, 15, 1920  0          ['batch_normalization_113[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_113 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_113[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_113 (TFOpLambda)  (None, 15, 15, 1920  0           ['tf.math.softplus_113[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_113 (TFOpLamb  (None, 15, 15, 1920  0          ['tf.convert_to_tensor_113[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_113[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_38 (G  (None, 1920)        0           ['tf.math.multiply_113[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_38 (Reshape)           (None, 1, 1, 1920)   0           ['global_average_pooling2d_38[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 1, 1, 80)     153680      ['reshape_38[0][0]']             \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_114 (TFOp  (None, 1, 1, 80)    0           ['conv2d_151[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.softplus_114 (TFOpLamb  (None, 1, 1, 80)    0           ['tf.convert_to_tensor_114[0][0]'\n",
            " da)                                                             ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_114 (TFOpLambda)  (None, 1, 1, 80)     0           ['tf.math.softplus_114[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_114 (TFOpLamb  (None, 1, 1, 80)    0           ['tf.convert_to_tensor_114[0][0]'\n",
            " da)                                                             , 'tf.math.tanh_114[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 1, 1, 1920)   155520      ['tf.math.multiply_114[0][0]']   \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 1, 1, 1920)   0           ['conv2d_152[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_38 (Multiply)         (None, 15, 15, 1920  0           ['activation_38[0][0]',          \n",
            "                                )                                 'tf.math.multiply_113[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 15, 15, 320)  614400      ['multiply_38[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 15, 15, 320)  1280       ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_29 (DropConnect)  (None, 15, 15, 320)  0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 15, 15, 320)  0           ['drop_connect_29[0][0]',        \n",
            "                                                                  'add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 15, 15, 1280  409600      ['add_29[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 15, 15, 1280  5120       ['conv2d_154[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_115 (TFOp  (None, 15, 15, 1280  0          ['batch_normalization_115[0][0]']\n",
            " Lambda)                        )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.softplus_115 (TFOpLamb  (None, 15, 15, 1280  0          ['tf.convert_to_tensor_115[0][0]'\n",
            " da)                            )                                ]                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_115 (TFOpLambda)  (None, 15, 15, 1280  0           ['tf.math.softplus_115[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_115 (TFOpLamb  (None, 15, 15, 1280  0          ['tf.convert_to_tensor_115[0][0]'\n",
            " da)                            )                                , 'tf.math.tanh_115[0][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling2d_39 (G  (None, 1280)        0           ['tf.math.multiply_115[0][0]']   \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1280)         0           ['global_average_pooling2d_39[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2562        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,558,886\n",
            "Trainable params: 11,450,182\n",
            "Non-trainable params: 108,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#%% Parameter\n",
        "\n",
        "#input_shape=(224,224,3) #이미지의 크기\n",
        "input_shape=(456,456,3)\n",
        "num_classes=2 #클래스의 숫자\n",
        "disease=[\"e\"]\n",
        "\n",
        "## resnet50 모델 5개를 각각 5개의질병에 적용 (a,b,c,d,e)\n",
        "\n",
        "model_e=EffNet(input_shape,num_classes)\n",
        "\n",
        "#%% 모델 요약\n",
        "\n",
        "model_e.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kudvMeWtEc3Y"
      },
      "outputs": [],
      "source": [
        "image_path=\"/content/drive/MyDrive/L_TL2/cat/eye/normal\"\n",
        "\n",
        "#윈도우에서 시행시에\n",
        "#image_path=\"C:/Users/VSA/Desktop/L_TL2/cat/eye/normal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6ywN_HKEvrj"
      },
      "outputs": [],
      "source": [
        "#categories 는 유/무 구별\n",
        "\n",
        "categories=[\"Y\",\"N\"] #0이 Y 1이 N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN-7KFopTIRI",
        "outputId": "45cc8195-c8d8-4671-878d-68d5367763e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1719, 456, 456, 3)\n",
            "(1719, 2)\n",
            "(191, 456, 456, 3)\n",
            "(191, 2)\n",
            "Epoch 1/200\n",
            "860/860 [==============================] - 255s 173ms/step - loss: 0.7851 - accuracy: 0.5236\n",
            "Epoch 2/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.7312 - accuracy: 0.5003\n",
            "Epoch 3/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.7133 - accuracy: 0.4945\n",
            "Epoch 4/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.7069 - accuracy: 0.5143\n",
            "Epoch 5/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.7003 - accuracy: 0.5207\n",
            "Epoch 6/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.7022 - accuracy: 0.5003\n",
            "Epoch 7/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.7036 - accuracy: 0.5003\n",
            "Epoch 8/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.7010 - accuracy: 0.4857\n",
            "Epoch 9/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.7053 - accuracy: 0.4910\n",
            "Epoch 10/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6976 - accuracy: 0.5177\n",
            "Epoch 11/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6989 - accuracy: 0.5096\n",
            "Epoch 12/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6979 - accuracy: 0.5055\n",
            "Epoch 13/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6943 - accuracy: 0.5323\n",
            "Epoch 14/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6889 - accuracy: 0.5550\n",
            "Epoch 15/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6931 - accuracy: 0.5509\n",
            "Epoch 16/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6901 - accuracy: 0.5439\n",
            "Epoch 17/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6962 - accuracy: 0.5311\n",
            "Epoch 18/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6853 - accuracy: 0.5765\n",
            "Epoch 19/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6839 - accuracy: 0.5759\n",
            "Epoch 20/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6832 - accuracy: 0.5858\n",
            "Epoch 21/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6936 - accuracy: 0.5439\n",
            "Epoch 22/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6821 - accuracy: 0.5905\n",
            "Epoch 23/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6883 - accuracy: 0.5707\n",
            "Epoch 24/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6937 - accuracy: 0.5241\n",
            "Epoch 25/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6975 - accuracy: 0.4968\n",
            "Epoch 26/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6965 - accuracy: 0.5166\n",
            "Epoch 27/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.6947 - accuracy: 0.5137\n",
            "Epoch 28/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.6962 - accuracy: 0.5247\n",
            "Epoch 29/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6917 - accuracy: 0.5346\n",
            "Epoch 30/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6928 - accuracy: 0.5492\n",
            "Epoch 31/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6927 - accuracy: 0.5358\n",
            "Epoch 32/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6972 - accuracy: 0.4962\n",
            "Epoch 33/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6970 - accuracy: 0.5073\n",
            "Epoch 34/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6830 - accuracy: 0.5829\n",
            "Epoch 35/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6889 - accuracy: 0.5439\n",
            "Epoch 36/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6790 - accuracy: 0.5852\n",
            "Epoch 37/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6742 - accuracy: 0.6044\n",
            "Epoch 38/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6723 - accuracy: 0.5963\n",
            "Epoch 39/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6476 - accuracy: 0.6417\n",
            "Epoch 40/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6582 - accuracy: 0.6178\n",
            "Epoch 41/200\n",
            "860/860 [==============================] - 147s 172ms/step - loss: 0.6465 - accuracy: 0.6492\n",
            "Epoch 42/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6648 - accuracy: 0.6155\n",
            "Epoch 43/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6526 - accuracy: 0.6422\n",
            "Epoch 44/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6494 - accuracy: 0.6539\n",
            "Epoch 45/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6564 - accuracy: 0.6335\n",
            "Epoch 46/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6445 - accuracy: 0.6411\n",
            "Epoch 47/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6497 - accuracy: 0.6446\n",
            "Epoch 48/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6564 - accuracy: 0.6277\n",
            "Epoch 49/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6482 - accuracy: 0.6289\n",
            "Epoch 50/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6491 - accuracy: 0.6318\n",
            "Epoch 51/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6396 - accuracy: 0.6521\n",
            "Epoch 52/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6419 - accuracy: 0.6306\n",
            "Epoch 53/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6440 - accuracy: 0.6289\n",
            "Epoch 54/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.6412 - accuracy: 0.6323\n",
            "Epoch 55/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6267 - accuracy: 0.6562\n",
            "Epoch 56/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6459 - accuracy: 0.6376\n",
            "Epoch 57/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.6397 - accuracy: 0.6632\n",
            "Epoch 58/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6406 - accuracy: 0.6417\n",
            "Epoch 59/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6157 - accuracy: 0.6655\n",
            "Epoch 60/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6162 - accuracy: 0.6702\n",
            "Epoch 61/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.6270 - accuracy: 0.6550\n",
            "Epoch 62/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.6161 - accuracy: 0.6638\n",
            "Epoch 63/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6045 - accuracy: 0.6707\n",
            "Epoch 64/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.6034 - accuracy: 0.6725\n",
            "Epoch 65/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.5994 - accuracy: 0.6824\n",
            "Epoch 66/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.5990 - accuracy: 0.6894\n",
            "Epoch 67/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.5722 - accuracy: 0.7062\n",
            "Epoch 68/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.5575 - accuracy: 0.7388\n",
            "Epoch 69/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.5496 - accuracy: 0.7341\n",
            "Epoch 70/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.5222 - accuracy: 0.7464\n",
            "Epoch 71/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.5341 - accuracy: 0.7499\n",
            "Epoch 72/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4894 - accuracy: 0.7830\n",
            "Epoch 73/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4928 - accuracy: 0.7725\n",
            "Epoch 74/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4911 - accuracy: 0.7725\n",
            "Epoch 75/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4723 - accuracy: 0.7882\n",
            "Epoch 76/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4694 - accuracy: 0.7999\n",
            "Epoch 77/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4709 - accuracy: 0.7929\n",
            "Epoch 78/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4524 - accuracy: 0.8051\n",
            "Epoch 79/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4620 - accuracy: 0.7976\n",
            "Epoch 80/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4536 - accuracy: 0.7999\n",
            "Epoch 81/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4568 - accuracy: 0.8109\n",
            "Epoch 82/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4424 - accuracy: 0.8005\n",
            "Epoch 83/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4428 - accuracy: 0.8010\n",
            "Epoch 84/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4142 - accuracy: 0.8290\n",
            "Epoch 85/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4329 - accuracy: 0.8162\n",
            "Epoch 86/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4200 - accuracy: 0.8330\n",
            "Epoch 87/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4338 - accuracy: 0.8168\n",
            "Epoch 88/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4035 - accuracy: 0.8325\n",
            "Epoch 89/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4288 - accuracy: 0.8179\n",
            "Epoch 90/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4069 - accuracy: 0.8255\n",
            "Epoch 91/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3929 - accuracy: 0.8389\n",
            "Epoch 92/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3908 - accuracy: 0.8400\n",
            "Epoch 93/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3880 - accuracy: 0.8365\n",
            "Epoch 94/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.4129 - accuracy: 0.8336\n",
            "Epoch 95/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3838 - accuracy: 0.8406\n",
            "Epoch 96/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3701 - accuracy: 0.8470\n",
            "Epoch 97/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3798 - accuracy: 0.8464\n",
            "Epoch 98/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3664 - accuracy: 0.8586\n",
            "Epoch 99/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3603 - accuracy: 0.8528\n",
            "Epoch 100/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3704 - accuracy: 0.8517\n",
            "Epoch 101/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3516 - accuracy: 0.8604\n",
            "Epoch 102/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.3559 - accuracy: 0.8528\n",
            "Epoch 103/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.3430 - accuracy: 0.8621\n",
            "Epoch 104/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.3266 - accuracy: 0.8749\n",
            "Epoch 105/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3449 - accuracy: 0.8662\n",
            "Epoch 106/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3356 - accuracy: 0.8592\n",
            "Epoch 107/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3272 - accuracy: 0.8668\n",
            "Epoch 108/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3314 - accuracy: 0.8674\n",
            "Epoch 109/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.3144 - accuracy: 0.8773\n",
            "Epoch 110/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.3210 - accuracy: 0.8732\n",
            "Epoch 111/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.3079 - accuracy: 0.8790\n",
            "Epoch 112/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2963 - accuracy: 0.8871\n",
            "Epoch 113/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2954 - accuracy: 0.8778\n",
            "Epoch 114/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2907 - accuracy: 0.8848\n",
            "Epoch 115/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.2571 - accuracy: 0.9081\n",
            "Epoch 116/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2759 - accuracy: 0.8976\n",
            "Epoch 117/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.2709 - accuracy: 0.8889\n",
            "Epoch 118/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2760 - accuracy: 0.8918\n",
            "Epoch 119/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2640 - accuracy: 0.9023\n",
            "Epoch 120/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2571 - accuracy: 0.9011\n",
            "Epoch 121/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2578 - accuracy: 0.9069\n",
            "Epoch 122/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2516 - accuracy: 0.9058\n",
            "Epoch 123/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2418 - accuracy: 0.9069\n",
            "Epoch 124/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2311 - accuracy: 0.9156\n",
            "Epoch 125/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2336 - accuracy: 0.9127\n",
            "Epoch 126/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2417 - accuracy: 0.9104\n",
            "Epoch 127/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1818 - accuracy: 0.9407\n",
            "Epoch 128/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2231 - accuracy: 0.9127\n",
            "Epoch 129/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.2178 - accuracy: 0.9186\n",
            "Epoch 130/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1885 - accuracy: 0.9366\n",
            "Epoch 131/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1941 - accuracy: 0.9232\n",
            "Epoch 132/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.2109 - accuracy: 0.9226\n",
            "Epoch 133/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.2067 - accuracy: 0.9255\n",
            "Epoch 134/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1978 - accuracy: 0.9314\n",
            "Epoch 135/200\n",
            "860/860 [==============================] - 147s 172ms/step - loss: 0.1853 - accuracy: 0.9348\n",
            "Epoch 136/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.2039 - accuracy: 0.9279\n",
            "Epoch 137/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1731 - accuracy: 0.9331\n",
            "Epoch 138/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.1522 - accuracy: 0.9471\n",
            "Epoch 139/200\n",
            "860/860 [==============================] - 147s 171ms/step - loss: 0.1770 - accuracy: 0.9331\n",
            "Epoch 140/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1592 - accuracy: 0.9424\n",
            "Epoch 141/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1787 - accuracy: 0.9331\n",
            "Epoch 142/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1472 - accuracy: 0.9476\n",
            "Epoch 143/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1522 - accuracy: 0.9453\n",
            "Epoch 144/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.1437 - accuracy: 0.9529\n",
            "Epoch 145/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.1300 - accuracy: 0.9517\n",
            "Epoch 146/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.1358 - accuracy: 0.9517\n",
            "Epoch 147/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1457 - accuracy: 0.9442\n",
            "Epoch 148/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1330 - accuracy: 0.9482\n",
            "Epoch 149/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1152 - accuracy: 0.9610\n",
            "Epoch 150/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1162 - accuracy: 0.9604\n",
            "Epoch 151/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1192 - accuracy: 0.9540\n",
            "Epoch 152/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0900 - accuracy: 0.9634\n",
            "Epoch 153/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1241 - accuracy: 0.9558\n",
            "Epoch 154/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1051 - accuracy: 0.9657\n",
            "Epoch 155/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1257 - accuracy: 0.9564\n",
            "Epoch 156/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1161 - accuracy: 0.9575\n",
            "Epoch 157/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0984 - accuracy: 0.9645\n",
            "Epoch 158/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1048 - accuracy: 0.9686\n",
            "Epoch 159/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0911 - accuracy: 0.9692\n",
            "Epoch 160/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0947 - accuracy: 0.9680\n",
            "Epoch 161/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0805 - accuracy: 0.9709\n",
            "Epoch 162/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0814 - accuracy: 0.9727\n",
            "Epoch 163/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1107 - accuracy: 0.9622\n",
            "Epoch 164/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0734 - accuracy: 0.9761\n",
            "Epoch 165/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.1286 - accuracy: 0.9564\n",
            "Epoch 166/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0709 - accuracy: 0.9721\n",
            "Epoch 167/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0642 - accuracy: 0.9767\n",
            "Epoch 168/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0985 - accuracy: 0.9663\n",
            "Epoch 169/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0841 - accuracy: 0.9721\n",
            "Epoch 170/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0869 - accuracy: 0.9657\n",
            "Epoch 171/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0809 - accuracy: 0.9727\n",
            "Epoch 172/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0721 - accuracy: 0.9756\n",
            "Epoch 173/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0659 - accuracy: 0.9738\n",
            "Epoch 174/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0534 - accuracy: 0.9796\n",
            "Epoch 175/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0693 - accuracy: 0.9750\n",
            "Epoch 176/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0981 - accuracy: 0.9663\n",
            "Epoch 177/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0465 - accuracy: 0.9855\n",
            "Epoch 178/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0875 - accuracy: 0.9668\n",
            "Epoch 179/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0458 - accuracy: 0.9831\n",
            "Epoch 180/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0706 - accuracy: 0.9756\n",
            "Epoch 181/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0747 - accuracy: 0.9756\n",
            "Epoch 182/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0857 - accuracy: 0.9703\n",
            "Epoch 183/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0567 - accuracy: 0.9825\n",
            "Epoch 184/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0685 - accuracy: 0.9791\n",
            "Epoch 185/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0709 - accuracy: 0.9773\n",
            "Epoch 186/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0335 - accuracy: 0.9884\n",
            "Epoch 187/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0821 - accuracy: 0.9738\n",
            "Epoch 188/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0622 - accuracy: 0.9785\n",
            "Epoch 189/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0463 - accuracy: 0.9866\n",
            "Epoch 190/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0438 - accuracy: 0.9872\n",
            "Epoch 191/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0877 - accuracy: 0.9756\n",
            "Epoch 192/200\n",
            "860/860 [==============================] - 149s 173ms/step - loss: 0.0277 - accuracy: 0.9948\n",
            "Epoch 193/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0579 - accuracy: 0.9831\n",
            "Epoch 194/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0838 - accuracy: 0.9703\n",
            "Epoch 195/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0582 - accuracy: 0.9796\n",
            "Epoch 196/200\n",
            "860/860 [==============================] - 148s 173ms/step - loss: 0.0685 - accuracy: 0.9767\n",
            "Epoch 197/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0492 - accuracy: 0.9837\n",
            "Epoch 198/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0547 - accuracy: 0.9802\n",
            "Epoch 199/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0424 - accuracy: 0.9884\n",
            "Epoch 200/200\n",
            "860/860 [==============================] - 148s 172ms/step - loss: 0.0622 - accuracy: 0.9802\n",
            "6/6 [==============================] - 7s 585ms/step - loss: 0.6290 - accuracy: 0.8482\n",
            "test accuracy: 0.8481675386428833\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#%% E모델 학습(안검염)\n",
        "\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for idx, cate in enumerate(categories):\n",
        "    label = [0 for _ in range(num_classes)]\n",
        "    label[idx] = 1\n",
        "    image_dir = image_path + '/e/'+cate+'/'\n",
        "\n",
        "    for top, dir, files in os.walk(image_dir):\n",
        "        i = 0\n",
        "        for filename in files:\n",
        "            if filename[-4:] != 'json':\n",
        "                i += 1\n",
        "                img = cv2.imread(image_dir + filename, 1)\n",
        "                #img = cv2.resize(img, (200, 200))\n",
        "                img = cv2.copyMakeBorder(img, 28, 28, 28, 28, cv2.BORDER_CONSTANT, value=0) #Zero padding 400->456\n",
        "                #img = cv2.copyMakeBorder(img, 12, 12, 12, 12, cv2.BORDER_CONSTANT, value=0)\n",
        "                X.append(img)\n",
        "                Y.append(label)\n",
        "\n",
        "X=np.array(X)\n",
        "X=X.astype(np.float32)/255.0\n",
        "Y=np.array(Y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "model_e.compile(optimizer=Adam(learning_rate=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "with tf.device('/GPU:0'):\n",
        "  history=model_e.fit(x_train,y_train,epochs=200,batch_size=2)\n",
        "test_loss,test_acc=model_e.evaluate(x_test,y_test)\n",
        "print(\"test accuracy:\",test_acc)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Train Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('TrainLoss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M8cKX1TnYQNA"
      },
      "outputs": [],
      "source": [
        "model_e.save(\"/content/drive/MyDrive/model_e.h5\")\n",
        "\n",
        "model_e.save_weights(\"/content/drive/MyDrive/model_e_weight.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qkPgfseANi2R"
      },
      "outputs": [],
      "source": [
        "K.clear_session()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}